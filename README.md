#  Checkpoint 2 â€“ Redes Neurais com Keras
  **Integrantes**
- Raphaela Oliveira Tatto - 554983
- Otavio Miklos - 554513
- Luciayla Kawakami - 557987
- Tiago Ribeiro Capela - 558021
##  Estrutura do RepositÃ³rio

```
CP2-IOT/
â”‚
â”œâ”€â”€ ex1_classificacao.py      # ExercÃ­cio 1 - ClassificaÃ§Ã£o (Wine Dataset)
â”œâ”€â”€ ex2_regressao.py          # ExercÃ­cio 2 - RegressÃ£o (California Housing)
â”œâ”€â”€ requirements.txt          # Lista de dependÃªncias para instalaÃ§Ã£o
â””â”€â”€ README.md                 # Este arquivo
```

---

##  Como Executar os Experimentos

1. **Clonar o repositÃ³rio**
```bash
git clone https://github.com/raphatatto/Redes-Neurais-com-Keras.git
cd cp2-iot
```

2. **Instalar as dependÃªncias**
```bash
pip install -r requirements.txt
```

3. **Rodar os scripts**
```bash
python ex1_classificacao.py
python ex2_regressao.py
```

---

##  ExercÃ­cio 1 â€“ ClassificaÃ§Ã£o Multiclasse (Wine Dataset)

- **ConfiguraÃ§Ã£o da Rede Neural:**
  - 2 camadas ocultas com 32 neurÃ´nios cada, ativaÃ§Ã£o **ReLU**
  - Camada de saÃ­da com 3 neurÃ´nios, ativaÃ§Ã£o **Softmax**
  - FunÃ§Ã£o de perda: `categorical_crossentropy`
  - Otimizador: **Adam**
  - Treinada por 50 Ã©pocas, batch size = 8

- **Resultados:**
  - **AcurÃ¡cia Rede Neural:** 1.0000
  - **AcurÃ¡cia RandomForest:** 1.0000

> **ConclusÃ£o:** Ambas as abordagens atingiram 100% de acurÃ¡cia no conjunto de teste.  
> Isso indica que o dataset Ã© bem separÃ¡vel e que tanto a rede neural quanto o RandomForest  
> conseguem aprender a fronteira de decisÃ£o de forma eficaz.

---

##  ExercÃ­cio 2 â€“ RegressÃ£o (California Housing Dataset)

- **ConfiguraÃ§Ã£o da Rede Neural:**
  - 3 camadas ocultas (64, 32, 16 neurÃ´nios) com ativaÃ§Ã£o **ReLU**
  - Camada de saÃ­da com 1 neurÃ´nio, ativaÃ§Ã£o **Linear**
  - FunÃ§Ã£o de perda: `mse`
  - Otimizador: **Adam**
  - Treinada por 50 Ã©pocas, batch size = 32

- **Resultados:**
  - **RMSE Rede Neural:** 0.8619
  - **RMSE LinearRegression:** 0.7456

> **ConclusÃ£o:** A regressÃ£o linear apresentou melhor desempenho que a rede neural,  
> provavelmente devido Ã  natureza quase linear das relaÃ§Ãµes entre as variÃ¡veis do dataset.  
> Uma rede neural poderia superar este resultado com mais ajustes de hiperparÃ¢metros  
> (maior nÃºmero de Ã©pocas, dropout, normalizaÃ§Ã£o de entrada, etc.).

---

## ðŸ“Š ComparaÃ§Ã£o Geral

| ExercÃ­cio | Modelo ClÃ¡ssico      | MÃ©trica  | Resultado | Rede Neural | Resultado |
|----------|---------------------|---------|-----------|------------|-----------|
| 1 â€“ ClassificaÃ§Ã£o | RandomForestClassifier | AcurÃ¡cia | **1.0000** | Keras NN | **1.0000** |
| 2 â€“ RegressÃ£o     | LinearRegression      | RMSE     | **0.7456** | Keras NN | 0.8619 |

---

##  ConclusÃ£o Final
- **ClassificaÃ§Ã£o:** Tanto modelos clÃ¡ssicos quanto redes neurais tÃªm desempenho perfeito neste dataset.
- **RegressÃ£o:** Modelos lineares ainda superam redes neurais neste conjunto, mas o uso de redes permite explorar relaÃ§Ãµes nÃ£o-lineares se houver maior complexidade ou mais dados.

---

##  DependÃªncias

Veja o arquivo [`requirements.txt`](./requirements.txt):

```
tensorflow>=2.15.0
numpy>=1.26.0
pandas>=2.2.0
scikit-learn>=1.5.0
matplotlib>=3.8.0
```

---

